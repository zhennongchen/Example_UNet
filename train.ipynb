{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''use two adajacent noisy slices as input, use current noisy slice as output reference'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append('/workspace/Documents')\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import CTDenoising_Diffusion_N2N.noise2noise.model as noise2noise\n",
    "import CTDenoising_Diffusion_N2N.functions_collection as ff\n",
    "import CTDenoising_Diffusion_N2N.Build_lists.Build_list as Build_list\n",
    "import CTDenoising_Diffusion_N2N.noise2noise.Generator as Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 1: define trial name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_name = 'noise2noise'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 2: define parameters (no need to change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = [512,512]\n",
    "num_patches_per_slice = 2\n",
    "patch_size = [128,128]\n",
    "\n",
    "histogram_equalization = True\n",
    "background_cutoff = -1000\n",
    "maximum_cutoff = 2000\n",
    "normalize_factor = 'equation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 3: build patient list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (136,) (136,) val: (32,) (32,)\n",
      "['/workspace/Documents/Data/denoising/fixedCT/00139437/0000258390/img_thinslice_partial.nii.gz'\n",
      " '/workspace/Documents/Data/denoising/fixedCT/00139437/0000258390/img_thinslice_partial.nii.gz'\n",
      " '/workspace/Documents/Data/denoising/fixedCT/00019599/0000029506/img_thinslice_partial.nii.gz'\n",
      " '/workspace/Documents/Data/denoising/fixedCT/00019599/0000029506/img_thinslice_partial.nii.gz'\n",
      " '/workspace/Documents/Data/denoising/fixedCT/00148611/0000455363/img_thinslice_partial.nii.gz'] ['/workspace/Documents/Data/denoising/simulation/00139437/0000258390/gaussian_random_0/recon.nii.gz'\n",
      " '/workspace/Documents/Data/denoising/simulation/00139437/0000258390/gaussian_random_1/recon.nii.gz'\n",
      " '/workspace/Documents/Data/denoising/simulation/00019599/0000029506/gaussian_random_0/recon.nii.gz'\n",
      " '/workspace/Documents/Data/denoising/simulation/00019599/0000029506/gaussian_random_1/recon.nii.gz'\n",
      " '/workspace/Documents/Data/denoising/simulation/00148611/0000455363/gaussian_random_0/recon.nii.gz'] ['/workspace/Documents/Data/denoising/fixedCT/00134441/0000455662/img_thinslice_partial.nii.gz'\n",
      " '/workspace/Documents/Data/denoising/fixedCT/00134441/0000455662/img_thinslice_partial.nii.gz'\n",
      " '/workspace/Documents/Data/denoising/fixedCT/00047802/0000455330/img_thinslice_partial.nii.gz'\n",
      " '/workspace/Documents/Data/denoising/fixedCT/00047802/0000455330/img_thinslice_partial.nii.gz'\n",
      " '/workspace/Documents/Data/denoising/fixedCT/00214844/0000455438/img_thinslice_partial.nii.gz'] ['/workspace/Documents/Data/denoising/simulation/00134441/0000455662/gaussian_random_0/recon.nii.gz'\n",
      " '/workspace/Documents/Data/denoising/simulation/00134441/0000455662/gaussian_random_1/recon.nii.gz'\n",
      " '/workspace/Documents/Data/denoising/simulation/00047802/0000455330/gaussian_random_0/recon.nii.gz'\n",
      " '/workspace/Documents/Data/denoising/simulation/00047802/0000455330/gaussian_random_1/recon.nii.gz'\n",
      " '/workspace/Documents/Data/denoising/simulation/00214844/0000455438/gaussian_random_0/recon.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "# change the excel path to your own path\n",
    "build_sheet =  Build_list.Build(os.path.join('/mnt/camca_NAS/denoising/Patient_lists/fixedCT_static_simulation_train_test_gaussian_local.xlsx'))\n",
    "_,_,_,_, condition_list_train, x0_list_train = build_sheet.__build__(batch_list = [0,1,2,3]) \n",
    " \n",
    "# define val\n",
    "_,_,_,_, condition_list_val, x0_list_val = build_sheet.__build__(batch_list = [4])\n",
    "\n",
    "print('train:', x0_list_train.shape, condition_list_train.shape, 'val:', x0_list_val.shape, condition_list_val.shape)\n",
    "print(x0_list_train[0:5], condition_list_train[0:5], x0_list_val[0:5], condition_list_val[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in out is :  [(16, 32), (32, 64), (64, 128), (128, 256)]\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "model = noise2noise.Unet2D(\n",
    "    init_dim = 16,\n",
    "    channels = 2, \n",
    "    out_dim = 1,\n",
    "    dim_mults = (2,4,8,16),\n",
    "    full_attn = (None,None, False, True),\n",
    "    act = 'ReLU',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load histogram equalization pre-saved files\n",
    "bins = np.load('/mnt/camca_NAS/denoising/Data/histogram_equalization/bins.npy') # change to your own path, they are in this repo as well (example data)\n",
    "bins_mapped = np.load('/mnt/camca_NAS/denoising/Data/histogram_equalization/bins_mapped.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_train = Generator.Dataset_2D(\n",
    "        img_list = condition_list_train, \n",
    "        image_size = image_size,\n",
    "\n",
    "        num_slices_per_image = 50,\n",
    "        random_pick_slice = True,\n",
    "        slice_range = None,\n",
    "\n",
    "        num_patches_per_slice = num_patches_per_slice,\n",
    "        patch_size = patch_size,\n",
    "\n",
    "        bins = bins,\n",
    "        bins_mapped = bins_mapped,\n",
    "        histogram_equalization = histogram_equalization,\n",
    "        background_cutoff = background_cutoff,\n",
    "        maximum_cutoff = maximum_cutoff,\n",
    "        normalize_factor = normalize_factor,\n",
    "\n",
    "        shuffle = True,\n",
    "        augment = True,\n",
    "        augment_frequency = 0.5,)\n",
    "\n",
    "generator_val = Generator.Dataset_2D(\n",
    "        img_list = condition_list_val,\n",
    "        image_size = image_size,\n",
    "\n",
    "        num_slices_per_image = 20,\n",
    "        random_pick_slice = False,\n",
    "        slice_range = [50,70],\n",
    "\n",
    "        num_patches_per_slice = 1,\n",
    "        patch_size = [512,512],\n",
    "\n",
    "        bins = bins,\n",
    "        bins_mapped = bins_mapped,\n",
    "        histogram_equalization = histogram_equalization,\n",
    "        background_cutoff = background_cutoff,\n",
    "        maximum_cutoff = maximum_cutoff,\n",
    "        normalize_factor = normalize_factor,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 6: train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define pretrained model path if any\n",
    "pre_trained_model = None#os.path.join('/mnt/camca_NAS/denoising/models', trial_name, 'models', 'model-13.pt')\n",
    "start_step = 0#13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "trainer = noise2noise.Trainer(\n",
    "    model= model,\n",
    "    generator_train = generator_train,\n",
    "    generator_val = generator_val,\n",
    "    train_batch_size = 25,\n",
    "\n",
    "    train_num_steps = 10000, # total training epochs\n",
    "    results_folder = os.path.join('/mnt/camca_NAS/denoising/models', trial_name, 'models'),\n",
    "   \n",
    "    train_lr = 1e-4,\n",
    "    train_lr_decay_every = 200, \n",
    "    save_models_every = 1,\n",
    "    validation_every = 1,\n",
    ")\n",
    "\n",
    "trainer.train(pre_trained_model=pre_trained_model, start_step= start_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
