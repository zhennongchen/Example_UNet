{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# make sure you have Github copilot installed, search it in the VSCode extension marketplace, it will make your coding much easier\n",
    "import sys \n",
    "sys.path.append('/host/d/Github/')\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import Example_UNet.model.model as model\n",
    "import Example_UNet.functions_collection as ff\n",
    "import Example_UNet.Build_lists.Build_list as Build_list\n",
    "import Example_UNet.Generator as Generator\n",
    "\n",
    "# if it says no module named ... (e.g., lpips), do the following:\n",
    "# 1. go to powershell, type wsl, enter wsl\n",
    "# 2. in wsl, type: sudo docker container ls, you will see the container id of your running container\n",
    "# 3. type: sudo docker container exec -it -u 0 <container_id> bash\n",
    "# 4. now you are inside the container root, type: pip install lpips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 1: define trial name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_name = 'trial'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 2: define parameters (no need to change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = [512,512]\n",
    "num_patches_per_slice = 2\n",
    "patch_size = [128,128]\n",
    "\n",
    "background_cutoff = -1000\n",
    "maximum_cutoff = 2000\n",
    "normalize_factor = 'equation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 3: build patient list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: (2,)  reference: (2,)\n",
      "input file example:  /host/d/Github/Example_UNet/example_data/data/ID_001/input.nii.gz  reference file:  /host/d/Github/Example_UNet/example_data/data/ID_001/output_reference.nii.gz\n"
     ]
    }
   ],
   "source": [
    "# change the excel path to your own path\n",
    "patient_list_spreadsheet = os.path.join('/host/d/Github/Example_UNet/example_data/Patient_lists/patient_list_example.xlsx')\n",
    "build_sheet =  Build_list.Build(patient_list_spreadsheet)\n",
    "_,_,input_file_train, reference_file_train = build_sheet.__build__(batch_list = [0,1]) \n",
    " \n",
    "# define val\n",
    "_,_,input_file_val, reference_file_val = build_sheet.__build__(batch_list = [1])  # just as an example, use the same batch for val\n",
    "\n",
    "print('input:', input_file_train.shape, ' reference:', reference_file_train.shape)\n",
    "print('input file example: ', input_file_train[0], ' reference file: ', reference_file_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in out is :  [(16, 32), (32, 64), (64, 128), (128, 256)]\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "our_model = model.Unet2D(\n",
    "    init_dim = 16,\n",
    "    channels = 1, \n",
    "    out_dim = 1,\n",
    "    dim_mults = (2,4,8,16),\n",
    "    full_attn = (None,None, False, True),\n",
    "    act = 'ReLU',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_train = Generator.Dataset_2D(\n",
    "        input_list = input_file_train,\n",
    "        reference_list = reference_file_train,\n",
    "\n",
    "        image_size = image_size,\n",
    "\n",
    "        num_slices_per_image = 50,\n",
    "        random_pick_slice = True,\n",
    "        slice_range = None, # None or [a,b]\n",
    "\n",
    "        background_cutoff = background_cutoff,\n",
    "        maximum_cutoff = maximum_cutoff,\n",
    "        normalize_factor = normalize_factor,\n",
    "\n",
    "        num_patches_per_slice = 2,\n",
    "        patch_size = patch_size, # train on patches\n",
    "\n",
    "        shuffle = True,\n",
    "        augment = True,\n",
    "        augment_frequency = 0.5,)\n",
    "\n",
    "generator_val = Generator.Dataset_2D(\n",
    "        input_list = input_file_train,\n",
    "        reference_list = reference_file_train,\n",
    "\n",
    "        image_size = image_size,\n",
    "\n",
    "        num_slices_per_image = 20,\n",
    "        random_pick_slice = False,\n",
    "        slice_range = [0,20], # None or [a,b]\n",
    "\n",
    "        background_cutoff = background_cutoff,\n",
    "        maximum_cutoff = maximum_cutoff,\n",
    "        normalize_factor = normalize_factor,\n",
    "\n",
    "        num_patches_per_slice = 1,\n",
    "        patch_size = image_size, ## validation on full image\n",
    "\n",
    "        shuffle = False,\n",
    "        augment = False,\n",
    "        augment_frequency = 0,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 6: train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pretrained model path if any\n",
    "pre_trained_model = None \n",
    "start_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "# first define a path to save your model, and create the folder\n",
    "model_save_path = os.path.join('/host/d/projects/Example_UNet/models', trial_name,'models')\n",
    "ff.make_folder([os.path.dirname(model_save_path), model_save_path])\n",
    "\n",
    "\n",
    "trainer = model.Trainer(\n",
    "    model= our_model,\n",
    "    generator_train = generator_train,\n",
    "    generator_val = generator_val,\n",
    "    train_batch_size = 5,\n",
    "\n",
    "    train_num_steps = 1000, # total training epochs\n",
    "    results_folder = model_save_path,\n",
    "   \n",
    "    train_lr = 1e-4,\n",
    "    train_lr_decay_every = 200,  # define your own lr decay frequency\n",
    "    save_models_every = 2, # define your own save frequency\n",
    "    validation_every = 2, # define your own validation frequency\n",
    ")\n",
    "\n",
    "trainer.train(pre_trained_model=pre_trained_model, start_step= start_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
